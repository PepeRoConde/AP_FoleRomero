











import tensorflow as tf
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt





from keras.datasets import cifar10

(x_train, y_train) , (x_test, y_test) = cifar10.load_data()








y_train = keras.utils.to_categorical(y_train, num_classes = 10)
y_test = keras.utils.to_categorical(y_test, num_classes = 10)





x_train = x_train / 255.0
x_test = x_test / 255.0





x_train = keras.layers.Flatten()(x_train)
x_test = keras.layers.Flatten()(x_test)














def plot(train, validation, title):
    plt.clf()
    epochs = range(1, len(train) + 1)
    
    plt.plot(epochs, train, 'b-o', label='Training ' + title)
    plt.plot(epochs, validation, 'r--o', label='Validation '+ title) 

    plt.title('Training and validation ' + title)
    plt.xlabel('Epochs')
    plt.ylabel(title)
    plt.legend()
    plt.show()








model = keras.Sequential(
    [
        keras.layers.Dense(3072, activation="relu"),
        keras.layers.Dense(3000, activation="relu"),
        keras.layers.Dense(2500, activation="relu"),
        keras.layers.Dense(1000, activation="relu"),
        keras.layers.Dense(40, activation="relu"),
        keras.layers.Dense(10, activation = "sigmoid"),
    ]
)
model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),
              loss=keras.losses.CategoricalCrossentropy(),
              metrics=[keras.metrics.CategoricalAccuracy()])
history = model.fit(
    x_train,
    y_train,
    epochs=50,
    batch_size=5000,
    validation_split = .1
)


print(model.evaluate(x_test, y_test))
plot(history.history['loss'], history.history['val_loss'], 'loss')
plot(history.history['categorical_accuracy'], history.history['val_categorical_accuracy'], 'categorical_accuracy')





model = keras.Sequential(
    [
        keras.layers.Dense(3072, activation="relu"),
        keras.layers.Dense(2100, activation="relu"),
        keras.layers.Dense(1000, activation="relu"),
        keras.layers.Dense(600, activation="relu"),
        keras.layers.Dense(640, activation="relu"),
        keras.layers.Dense(205, activation="relu"),
        keras.layers.Dense(70, activation="relu"),
        keras.layers.Dense(10, activation = "sigmoid"),
    ]
)
model.compile(optimizer=keras.optimizers.Adam(learning_rate=5e-5),
              loss=keras.losses.CategoricalCrossentropy(),
              metrics=[keras.metrics.CategoricalAccuracy()])
history = model.fit(
    x_train,
    y_train,
    epochs=50,
    batch_size=3000,
    validation_split = .1
)


print(model.evaluate(x_test, y_test))
plot(history.history['loss'], history.history['val_loss'], 'loss')
plot(history.history['categorical_accuracy'], history.history['val_categorical_accuracy'], 'categorical_accuracy')





modelSGD = keras.Sequential(
    [
        keras.layers.Dense(3072, activation="relu"),
        keras.layers.Dense(2100, activation="relu" ),
        keras.layers.Dense(1000, activation="relu"),
        keras.layers.Dense(600, activation="relu"),
        keras.layers.Dense(640, activation="relu"),
        keras.layers.Dense(205, activation="relu"),
        keras.layers.Dense(70, activation="relu"),
        keras.layers.Dense(10, activation = "sigmoid"),
    ]
)
modelSGD.compile(optimizer=keras.optimizers.SGD(learning_rate=1e-2),
              loss=keras.losses.CategoricalCrossentropy(),
              metrics=[keras.metrics.CategoricalAccuracy()])



history = modelSGD.fit(
    x_train,
    y_train,
    epochs=50,
    batch_size=3000,
    validation_split = .1
)


print(modelSGD.evaluate(x_test, y_test))
plot(history.history['loss'], history.history['val_loss'], 'loss')
plot(history.history['categorical_accuracy'], history.history['val_categorical_accuracy'], 'categorical_accuracy')





model = keras.Sequential(
    [
        keras.layers.Dense(3072, activation="relu"),
        keras.layers.Dense(1500, activation="relu" ),
        keras.layers.Dense(1015, activation="relu", kernel_regularizer=regularizers.l2(0.026)),
        keras.layers.Dense(550, activation="relu", kernel_regularizer=regularizers.l2(0.019)),
        keras.layers.Dense(740, activation="relu", kernel_regularizer=regularizers.l2(0.017)),
        keras.layers.Dense(115, activation="relu", kernel_regularizer=regularizers.l2(0.027)),
        keras.layers.Dense(50, activation="relu", kernel_regularizer=regularizers.l2(0.008)),
        keras.layers.Dense(40, activation="relu", kernel_regularizer=regularizers.l2(0.001)),
        keras.layers.Dense(10, activation = "sigmoid"),
    ]
)
model.compile(optimizer=keras.optimizers.Adagrad(learning_rate=1e-2),
              loss=keras.losses.CategoricalCrossentropy(),
              metrics=[keras.metrics.CategoricalAccuracy()])



history = model.fit(
    x_train,
    y_train,
    epochs=50,
    batch_size=10000,
    validation_split = .1
)


print(model.evaluate(x_test, y_test))X
plot(history.history['loss'], history.history['val_loss'], 'loss')
plot(history.history['categorical_accuracy'], history.history['val_categorical_accuracy'], 'categorical_accuracy')











from keras import regularizers





modelDropout = keras.Sequential(
    [
        keras.layers.Dense(3072, activation="relu"),
        keras.layers.Dense(2100, activation="relu"),
        keras.layers.Dropout(0.3),
        keras.layers.Dense(1000, activation="relu"),
        keras.layers.Dropout(0.2),
        keras.layers.Dense(600, activation="relu"),
        keras.layers.Dropout(0.1),
        keras.layers.Dense(640, activation="relu"),
        keras.layers.Dropout(0.1),
        keras.layers.Dense(205, activation="relu"),
        keras.layers.Dropout(0.1),
        keras.layers.Dense(70, activation="relu"),
        keras.layers.Dropout(0.1),
        keras.layers.Dense(10, activation = "sigmoid"),
    ]
)
modelDropout.compile(optimizer=keras.optimizers.Adam(learning_rate=5e-5),
              loss=keras.losses.CategoricalCrossentropy(),
              metrics=[keras.metrics.CategoricalAccuracy()])
history = modelDropout.fit(
    x_train,
    y_train,
    epochs=50,
    batch_size=3000,
    validation_split = .1
)


print(modelDropout.evaluate(x_test, y_test))
plot(history.history['loss'], history.history['val_loss'], 'loss')
plot(history.history['categorical_accuracy'], history.history['val_categorical_accuracy'], 'categorical_accuracy')











modelL1 = keras.Sequential(
    [
        keras.layers.Dense(3072, activation="relu", kernel_regularizer=regularizers.l1(0.0001)),
        keras.layers.Dense(2100, activation="relu", kernel_regularizer=regularizers.l1(0.0001)),
        keras.layers.Dense(1000, activation="relu", kernel_regularizer=regularizers.l1(0.0001)),
        keras.layers.Dense(600, activation="relu", kernel_regularizer=regularizers.l1(0.0001)),
        keras.layers.Dense(640, activation="relu", kernel_regularizer=regularizers.l1(0.0001)),
        keras.layers.Dense(205, activation="relu", kernel_regularizer=regularizers.l1(0.0001)),
        keras.layers.Dense(70, activation="relu", kernel_regularizer=regularizers.l1(0.0001)),
        keras.layers.Dense(10, activation = "sigmoid"),
    ]
)
modelL1.compile(optimizer=keras.optimizers.Adam(learning_rate=5e-5),
              loss=keras.losses.CategoricalCrossentropy(),
              metrics=[keras.metrics.CategoricalAccuracy()])
historyL1 = modelL1.fit(
    x_train,
    y_train,
    epochs=80,
    batch_size=3000,
    validation_split = .1
)


print(modelL1.evaluate(x_test, y_test))
plot(historyL1.history['loss'], historyL1.history['val_loss'], 'loss')
plot(historyL1.history['categorical_accuracy'], historyL1.history['val_categorical_accuracy'], 'categorical_accuracy')











modelL2 = keras.Sequential(
    [
        keras.layers.Dense(3072, activation="relu", kernel_regularizer=regularizers.l2(0.0001)),
        keras.layers.Dense(2100, activation="relu", kernel_regularizer=regularizers.l2(0.0001)),
        keras.layers.Dense(1000, activation="relu", kernel_regularizer=regularizers.l2(0.0001)),
        keras.layers.Dense(600, activation="relu", kernel_regularizer=regularizers.l2(0.0001)),
        keras.layers.Dense(640, activation="relu", kernel_regularizer=regularizers.l2(0.0001)),
        keras.layers.Dense(205, activation="relu", kernel_regularizer=regularizers.l2(0.0001)),
        keras.layers.Dense(70, activation="relu", kernel_regularizer=regularizers.l2(0.0001)),
        keras.layers.Dense(10, activation = "sigmoid"),
    ]
)
modelL2.compile(optimizer=keras.optimizers.Adam(learning_rate=5e-5),
              loss=keras.losses.CategoricalCrossentropy(),
              metrics=[keras.metrics.CategoricalAccuracy()])
historyL2 = modelL2.fit(
    x_train,
    y_train,
    epochs=80,
    batch_size=3000,
    validation_split = .1
)


print(modelL2.evaluate(x_test, y_test))
plot(historyL2.history['loss'], historyL2.history['val_loss'], 'loss')
plot(historyL2.history['categorical_accuracy'], historyL2.history['val_categorical_accuracy'], 'categorical_accuracy')








ElasticNet = keras.Sequential(
    [
        keras.layers.Dense(3072, activation="relu", kernel_regularizer=regularizers.L1L2(l1=0.0001,l2=0.0001)),
        keras.layers.Dense(2100, activation="relu", kernel_regularizer=regularizers.L1L2(l1=0.0001,l2=0.0001)),
        keras.layers.Dense(1000, activation="relu", kernel_regularizer=regularizers.L1L2(l1=0.0001,l2=0.0001)),
        keras.layers.Dense(600, activation="relu", kernel_regularizer=regularizers.L1L2(l1=0.0001,l2=0.0001)),
        keras.layers.Dense(640, activation="relu", kernel_regularizer=regularizers.L1L2(l1=0.0001,l2=0.0001)),
        keras.layers.Dense(205, activation="relu", kernel_regularizer=regularizers.L1L2(l1=0.0001,l2=0.0001)),
        keras.layers.Dense(70, activation="relu", kernel_regularizer=regularizers.L1L2(l1=0.0001,l2=0.0001)),
        keras.layers.Dense(10, activation = "sigmoid"),
    ]
)
ElasticNet.compile(optimizer=keras.optimizers.Adam(learning_rate=5e-5),
              loss=keras.losses.CategoricalCrossentropy(),
              metrics=[keras.metrics.CategoricalAccuracy()])
historyEL = ElasticNet.fit(
    x_train,
    y_train,
    epochs=80,
    batch_size=3000,
    validation_split = .1
)


print(ElasticNet.evaluate(x_test, y_test))
plot(historyEL.history['loss'], historyEL.history['val_loss'], 'loss')
plot(historyEL.history['categorical_accuracy'], historyEL.history['val_categorical_accuracy'], 'categorical_accuracy')



