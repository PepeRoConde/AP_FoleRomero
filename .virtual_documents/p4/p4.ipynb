














import pandas as pd # siguiendo la convención universal
from matplotlib import pyplot as plt
import numpy as np
from scipy import stats
import os
import datetime
from tensorflow.keras import layers, models,metrics, losses,optimizers
from tensorflow import keras
import seaborn as sns








if "USD_EUR.json" in os.listdir():
    df = pd.read_json("USD_EUR.json") # usando df para seguir la convención


df.describe() # les echamos un ojo





plt.plot(df[["precio mas alto"]]);





columnasFiltrar = ['precio inicio', 'precio mas alto', 'precio mas bajo', 'precio fin', 'volumen', 'volumen en cuotas', 'volumen en cuotas', 'numero de compras', 'volumen de dolares', 'volumen de euros']

df = df[(np.abs(stats.zscore(df[columnasFiltrar])) < 1.8).all(axis=1)]


plt.plot(df[["precio mas alto"]]);





plot_cols = ['precio inicio', 'precio fin', 'numero de compras']
plot_features = df[plot_cols]
plot_features.index = df['timestamp inicial']
_ = plot_features.plot(subplots=True)

plot_features = df[plot_cols][:]
plot_features.index = df['timestamp inicial'][:]
_ = plot_features.plot(subplots=True)


df.head()





hora = pd.Timedelta(seconds=3600)
fechas = df[:-1]['timestamp inicial']
fechassegundos = pd.to_datetime(fechas, format='%d.%m.%Y %H:%M:%S')
instancias = []
diferencias = []
cadahora = True

for i in range(len(fechassegundos) - 1):  # Hasta el penúltimo índice
    if (fechassegundos.iloc[i + 1] - fechassegundos.iloc[i]) != hora:
        instancias.append(i)
        cadahora = False
        diferencias.append((fechassegundos.iloc[i + 1] - fechassegundos.iloc[i]).total_seconds())

print(instancias, diferencias, cadahora, sep = '\n\n')

plt.hist(diferencias)





len(instancias)/len(df)





print(df[85:87]['timestamp inicial'])





instanteSeparacion = pd.to_datetime("31/08/2022 23:59:59", dayfirst=True)
dfEntrenamiento = df[df['timestamp inicial'] <= instanteSeparacion]
dfTest = df[df['timestamp inicial'] > instanteSeparacion]


print(dfEntrenamiento.head())











def ajustar_fechas(dataset):
    #Sacamos los valores de las fechas (inicial y final)
    date_time_inicial = pd.to_datetime(dataset.pop('timestamp inicial'), format='%d.%m.%Y %H:%M:%S')
    # Los pasamos a segundos
    timestamp_s_inicial = date_time_inicial.map(pd.Timestamp.timestamp)
    #Segundos en un dia y un año
    day = 24 * 60 * 60
    year = 365 * day

    # TODO: Extrae, para cada fecha, el seno y el coseno, y añádelos al dataframe
    dataset['Dia sin inic'] = np.sin(2 * np.pi * (timestamp_s_inicial % day) / day)
    dataset['Dia cos inic'] = np.cos(2 * np.pi * (timestamp_s_inicial % day) / day)
    dataset['Anho sin inic'] = np.sin(2 * np.pi * (timestamp_s_inicial % year) / year)
    dataset['Anho cos inic'] = np.cos(2 * np.pi * (timestamp_s_inicial % year) / year)

    dataset.pop('timestamp final')

    return dataset


dfEntrenamiento = ajustar_fechas(dfEntrenamiento)
dfTest = ajustar_fechas(dfTest)


print(dfEntrenamiento.head())


columnasNormalizar = ['volumen', 'volumen en cuotas','numero de compras', 'volumen de dolares', 'volumen de euros']
datasets = [dfEntrenamiento, dfTest]
for df in datasets:
    for col in columnasNormalizar:
        df[col] = (df[col] - df[col].mean()) / df[col].std()



print(dfEntrenamiento.head())





df_std = dfEntrenamiento.melt(var_name='Column', value_name='Normalized')
plt.figure(figsize=(12, 6))
ax = sns.violinplot(x='Column', y='Normalized', data=df_std)
_ = ax.set_xticklabels(dfEntrenamiento.keys(), rotation=90)





dfEntrenamiento['precio en 6h'] = dfEntrenamiento['precio inicio'].shift(-6)

dfEntrenamiento['accion'] = dfEntrenamiento.apply(lambda row: 1 if row['precio en 6h'] > row['precio inicio'] else 0, axis=1)



dfTest['precio en 6h'] = dfTest['precio inicio'].shift(-6)

dfTest['accion'] = dfTest.apply(lambda row: 1 if row['precio en 6h'] > row['precio inicio'] else 0, axis=1)


print(dfEntrenamiento[-10:])





dfEntrenamiento = dfEntrenamiento[0:-6]


dfTest = dfTest[0:-6]


dfEntrenamiento[-6:]


plt.figure(figsize=(25,5))
plt.plot(dfEntrenamiento['precio en 6h'])
plt.plot(dfEntrenamiento['precio inicio'])
plt.scatter(range(len(dfEntrenamiento['accion'])),dfEntrenamiento['accion'],s=.001)





dfEntrenamientoNP = dfEntrenamiento.to_numpy()
dfTestNP = dfTest.to_numpy()








def sliding_window(data, labels1, labels2, input_width, label_width=1, offset=0):
    x = []
    y = []
    z = []
    # Corrección en el rango del bucle
    for i in range(len(data) - input_width - label_width - offset + 1):
        # Seleccionar la ventana de entrada y etiquetas
        _x = data[i:i + input_width]
        _y = labels1[i + input_width + offset:i + input_width + offset + label_width]
        _z = labels2[i + input_width + offset:i + input_width + offset + label_width]
        x.append(_x)
        y.append(_y)
        z.append(_z)
    # Convertir a numpy arrays
    x, y, z = np.array(x), np.array(y), np.array(z)

    # Añadir nueva dimensión si es necesario
    if len(x.shape) == 2:  # Si x es 2D, hazlo 3D
        x = x[:, :, np.newaxis]

    if len(y.shape) == 2:  # Si y es 2D, hazlo 3D
        y = y[:, :, np.newaxis]

    if len(z.shape) == 2:  # Si y es 2D, hazlo 3D
        z = z[:, :, np.newaxis]


    return x, y, z





input_width = 24
label_width = 24
offset = 0



# TODO: Llama a la función para dividir el dataset
x_train, y_train1 , y_train2 = sliding_window(
    dfEntrenamientoNP[:,0:-2],  # Datos de entrada sin la etiqueta objetivo
    dfEntrenamientoNP[:,-2:-1],
    dfEntrenamientoNP[:,-1:],
    input_width=input_width,
    label_width=label_width,
    offset=offset
)

x_test, y_test1 , y_test2 = sliding_window(
    dfTestNP[:,0:-2],  # Datos de entrada sin la etiqueta objetivo
    dfTestNP[:,-2:-1],
    dfTestNP[:,-1:],
    input_width=input_width,
    label_width=label_width,
    offset=offset
)








numero_caracteristicas = dfEntrenamientoNP.shape[1]-2


x_train.shape





callback  = keras.callbacks.EarlyStopping(
    monitor="val_regresion_binary_accuracy",  #metrica a monitorizar
    mode='max',
    patience=40,     #nº de ciclos sin mejora antes de parar
    restore_best_weights=True   #devolver el modelo que mejor metrica tuvo
)










input_layer = keras.Input(shape=(input_width,numero_caracteristicas))
shared_layer = layers.Dense(32, activation='relu')(input_layer)

output1 = layers.Dense(2, activation='softmax', name='clasificacion')(shared_layer)  # Clasificación
output2 = layers.Dense(1, activation='linear', name='regresion')(shared_layer)  # Regresión

modeloDenso = keras.Model(inputs=input_layer, outputs=[output1, output2])

modeloDenso.compile(loss=losses.MeanSquaredError(),
                  optimizer=optimizers.Adam(learning_rate=0.005),
                  metrics=[metrics.MeanAbsoluteError(), metrics.MeanSquaredError()])

modeloDenso.fit(x_train,
                {'clasificacion': y_train1, 'regresion': y_train2},
                callbacks = callback,
                epochs = 100, 
                validation_split = 0.2,
                batch_size=20848)


loss, loss_output1, loss_output2, acc_output1, mae_output2 = modeloDenso.evaluate(
    x_test,
    {'clasificacion': y_test1, 'regresion': y_test2}
)











input_layer = keras.Input(shape=(input_width,numero_caracteristicas))
shared_layer = layers.LSTM(32, return_sequences = True)(input_layer)

output1 = layers.Dense(2, activation='softmax', name='clasificacion')(shared_layer)  # Clasificación
output2 = layers.Dense(1, activation='linear', name='regresion')(shared_layer)  # Regresión

modeloLSTM = keras.Model(inputs=input_layer, outputs=[output1, output2])

modeloLSTM.compile(loss=losses.MeanSquaredError(),
                  optimizer=optimizers.Adagrad(),
                  metrics=[metrics.MeanAbsoluteError(),metrics.BinaryAccuracy()])


input_layer = keras.Input(shape=(input_width,numero_caracteristicas))
shared_layer = layers.GRU(32, return_sequences = True)(input_layer)

output1 = layers.Dense(2, activation='softmax', name='clasificacion')(shared_layer)  # Clasificación
output2 = layers.Dense(1, activation='linear', name='regresion')(shared_layer)  # Regresión

modeloGRU = keras.Model(inputs=input_layer, outputs=[output1, output2])

modeloGRU.compile(loss=losses.MeanSquaredError(),
                  optimizer=optimizers.Adagrad(),
                  metrics=[metrics.MeanAbsoluteError(),metrics.BinaryAccuracy()])


histLSTM = modeloLSTM.fit(x_train,
                {'clasificacion': y_train1, 'regresion': y_train2},
                callbacks = callback,
                epochs = 100, 
                validation_split = 0.2,
                batch_size=16384)


histGRU = modeloGRU.fit(x_train,
                {'clasificacion': y_train1, 'regresion': y_train2},
                callbacks = callback,
                epochs = 100, 
                validation_split = 0.2,
                batch_size=16384)


modeloGRU.fit(x_train,{'clasificacion': y_train1, 'regresion': y_train2},callbacks = callback,epochs = 100, validation_split = 0.2)


loss, loss_output1, loss_output2, acc_output1, mae_output2 = modeloLSTM.evaluate(
    x_test,
    {'clasificacion': y_test1, 'regresion': y_test2}
)


loss, loss_output1, loss_output2, acc_output1, mae_output2 = modeloGRU.evaluate(
    x_test,
    {'clasificacion': y_test1, 'regresion': y_test2}
)


plt.plot(histGRU.history['val_regresion_loss'],label='GRU val_regresion_loss')
plt.plot(histGRU.history['val_clasificacion_loss'],label='GRU val_clasificacion_loss')
plt.plot(histLSTM.history['val_regresion_loss'],label='LSTM val_regresion_loss')
plt.plot(histLSTM.history['val_clasificacion_loss'],label='LSTM val_clasificacion_loss')
plt.legend();


#plt.plot(histGRU.history['val_clasificacion_mean_absolute_error'],label='val gru clasificacion_mean_absolute_error')
plt.plot(histGRU.history['val_regresion_binary_accuracy'],label='val gru regresion regresion_binary_accuracy')
#plt.plot(histLSTM.history['val_clasificacion_mean_absolute_error'],label='val lstm clasificacion_mean_absolute_error')
plt.plot(histLSTM.history['val_regresion_binary_accuracy'],label='val lstm regresion regresion_binary_accuracy')
#plt.plot(histGRU.history['clasificacion_mean_absolute_error'],label='gru clasificacion_mean_absolute_error')
plt.plot(histGRU.history['regresion_binary_accuracy'],label='gru regresion regresion_binary_accuracy')
#plt.plot(histLSTM.history['clasificacion_mean_absolute_error'],label='lstm clasificacion_mean_absolute_error')
plt.plot(histLSTM.history['regresion_binary_acauracy'],label='lstm regresion regresion_binary_accuracy')
plt.legend();





input_layer = keras.Input(shape=(input_width,numero_caracteristicas))
x = layers.LSTM(128, return_sequences = True)(input_layer)
shared_layer = layers.GRU(16, return_sequences = True)(x)

output1 = layers.Dense(2, activation='softmax', name='clasificacion')(shared_layer)  # Clasificación
output2 = layers.Dense(1, activation='linear', name='regresion')(shared_layer)  # Regresión

modeloAnidado = keras.Model(inputs=input_layer, outputs=[output1, output2])

modeloAnidado.compile(loss=losses.MeanSquaredError(),
                  optimizer=optimizers.Adam(learning_rate = 0.15),
                  metrics=[metrics.MeanAbsoluteError(),metrics.BinaryAccuracy()])





histAnidado = modeloAnidado = modeloGRU.fit(x_train,
                {'clasificacion': y_train1, 'regresion': y_train2},
                callbacks = callback,
                epochs = 600, 
                validation_split = 0.05,
                batch_size=20848)


plt.plot(histAnidado.history['val_regresion_binary_accuracy'],label='val anidado regresion regresion_binary_accuracy')
plt.plot(histAnidado.history['regresion_binary_accuracy'],label='anidado regresion regresion_binary_accuracy')

plt.legend();


test_loss = modeloAnidado.evaluate(x_test, y_test)


prediccion = modeloAnidado.predict(x_test)



























