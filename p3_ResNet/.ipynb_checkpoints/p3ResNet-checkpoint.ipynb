{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce4b2a7e-7a28-4df6-989f-b2df7cb63fe6",
   "metadata": {},
   "source": [
    "# Redes de Neuronas con conexiones residuales y entrenados según _transfer learning_\n",
    "## Práctica 3\n",
    "\n",
    "#### Hugo Fole Avellás y José Romero Conde"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d7a49d-451a-4f55-bbc7-4337319a9cf0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0782e9-0a87-4281-96f2-d5157ae3acae",
   "metadata": {},
   "source": [
    " ### $\\text{Ejercicio } 1$  \n",
    " ### (_2 puntos_) Define la capa ResidualBlock (ver Figura 2), usando como base la plantilla proporcionada en la Figura 3.\n",
    " - Ten en cuenta que el número de convoluciones depende de los valores de input_channels y out-put_channels.\n",
    " - Esta red no tiene capas de Pooling. La reducción del tamaño se realiza con el parámetro strides\n",
    "de las convoluciones, pero se modifica únicamente en 1 (o 2) de las convoluciones del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04184d0-0eaf-4b05-b7b8-705e21ca01bd",
   "metadata": {},
   "source": [
    "!['arquitectura'](ResidualBlock.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca344b58-a57f-4a04-be96-188b7bca3740",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plantilla\n",
    "\n",
    "#class ResidualBlock(Model):\n",
    "#   def __init__(self, input_channels, output_channels, strides=(1, 1)):\n",
    "#       ...\n",
    "#    def call(self, x):\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9398cfad-f693-4682-a776-417f4ae112ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo https://keras.io/guides/making_new_layers_and_models_via_subclassing/\n",
    "#\n",
    "#class ResNet(keras.Model):\n",
    "#\n",
    "#    def __init__(self, num_classes=1000):\n",
    "#        super().__init__()\n",
    "#        self.block_1 = ResNetBlock()\n",
    "#        self.block_2 = ResNetBlock()\n",
    "#        self.global_pool = layers.GlobalAveragePooling2D()\n",
    "#        self.classifier = Dense(num_classes)\n",
    "#\n",
    "#    def call(self, inputs):\n",
    "#        x = self.block_1(inputs)\n",
    "#        x = self.block_2(x)\n",
    "#        x = self.global_pool(x)\n",
    "#        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3b4d6140-6e4b-4812-9c5b-6b69730b17a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations\n",
    "\n",
    "class ResidualBlock(Model):\n",
    "    def __init__(self, input_channels, output_channels, strides=(1, 1)):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.BN1 = layers.BatchNormalization()\n",
    "        self.Conv1 = layers.Conv2D(filters = output_channels, \n",
    "                                   kernel_size = (1, 1),\n",
    "                                   strides = strides,)\n",
    "        self.BN2 = layers.BatchNormalization()\n",
    "        self.Conv2 = layers.Conv2D(filters = output_channels, \n",
    "                                   kernel_size = (1, 1),\n",
    "                                   strides = (1, 1))\n",
    "        \n",
    "        if input_channels != output_channels:\n",
    "            self.salidaDistinta = True\n",
    "            self.ConvFuera = layers.Conv2D(filters = output_channels, \n",
    "                                   kernel_size = (1, 1),\n",
    "                                   strides = strides)\n",
    "        else: self.salidaDistinta = False\n",
    "            \n",
    "    def call(self, x):\n",
    "        x = self.BN1(x)\n",
    "        y = activations.silu(x)\n",
    "        x = self.Conv1(y)\n",
    "        x = self.BN2(x)\n",
    "        x = activations.silu(x)\n",
    "        x = self.Conv2(x)\n",
    "        if self.salidaDistinta:\n",
    "            y = self.ConvFuera(y)\n",
    "        x = x + y\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c138fe8-eb0f-4fbf-b55e-58246474cd34",
   "metadata": {},
   "source": [
    " ### $\\text{Ejercicio } 2$  \n",
    "### (_2 puntos_) Define la red ResidualNetwork (ver Figura 1). Para comprobar su correcto funcionamiento haz lo siguiente:\n",
    " - Descarga los pesos del modelo preentrenado (los podrás encontrar en el canal de Teams de la asignatura).\n",
    " - Carga los pesos en tu modelo, haciendo uso de la función proporcionada en la Figura 4.\n",
    " - Comprueba que la precisión del modelo en CIFAR-100 es superior al 69 %."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c77615-3123-4342-af5c-75949f51bf14",
   "metadata": {},
   "source": [
    "!['arquitectura'](ResidualNetwork.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a7e2d100-07f8-4029-a634-0063bc4a3894",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "\n",
    "ResidualNetwork = Sequential([\n",
    "    layers.Conv2D(filters=16, kernel_size=(3,3),strides=(1,1),padding=\"same\"), \n",
    "    # la configuración de la capa convolucional es para asegurarse que no se reduce tamaño\n",
    "    ResidualBlock(16,64),\n",
    "    ResidualBlock(64,64),\n",
    "    ResidualBlock(64,64),\n",
    "    ResidualBlock(64,128),\n",
    "    ResidualBlock(128,128),\n",
    "    ResidualBlock(128,128),\n",
    "    ResidualBlock(128,256),\n",
    "    ResidualBlock(256,256),\n",
    "    ResidualBlock(256,256),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation(activations.silu),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(100)\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "22577e69-b36b-407c-ad07-fc4949ca0adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def load_weights(model, weight_file):\n",
    "    with open(weight_file, 'rb') as f:\n",
    "        weights = pickle.load(f)\n",
    "\n",
    "    all_vars = model.trainable_weights + model.non_trainable_weights\n",
    "    weight_list = [(x, weights[x]) for x in sorted(weights.keys())]\n",
    "    weights = {}\n",
    "    for i, var in enumerate(all_vars):\n",
    "        aux = var.path.split('/')[-2:]\n",
    "        classname = '_'.join(aux[0].split('_')[:-1])\n",
    "        name = aux[1]\n",
    "        assigned = False\n",
    "        for j, (key, value) in enumerate(weight_list):\n",
    "            if classname in key and name in key:\n",
    "                try:\n",
    "                    all_vars[i].assign(value)\n",
    "                except:\n",
    "                    continue\n",
    "                print('assinging', key, 'to', var.path)\n",
    "                del weight_list[j]\n",
    "                assigned = True\n",
    "                break\n",
    "        if not assigned:\n",
    "            raise Exception(var.path + ' cannot be loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e84ade66-b928-42be-bd8a-469e7bda95c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_weights(ResidualNetwork, \"p2_model_weights.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a4c97ae3-b928-4cd7-b7b8-e014b768726d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, -1.0, 1.0, -1.0)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## carga y procesado de datos\n",
    "\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "import numpy as np\n",
    "\n",
    "(x_train, Y_train), (x_test, Y_test) = cifar100.load_data()\n",
    "\n",
    "x_train = (2*x_train.astype(float)-255)/(255)\n",
    "x_test = (2*x_test.astype(float)-255)/(255)\n",
    "\n",
    "# como la salida de la red son 100 nodos se sobreentiende \n",
    "# que tengo que one-hot-ear Y\n",
    "\n",
    "y_train = np.zeros(shape=(Y_train.shape[0],max(Y_train)[0]+1))\n",
    "y_train[np.arange(Y_train.size),Y_train] = 1\n",
    "\n",
    "(np.max(x_train),np.min(x_train),np.max(x_test),np.min(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a8db39f7-0d1b-443a-98e1-b5ddb65342ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 49997, 49998, 49999])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(Y_train.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "919a7c33-d383-44da-b425-c6ab5b27d750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import CategoricalCrossentropy as CCE\n",
    "\n",
    "ResidualNetwork.compile(optimizer='adam',\n",
    "                        loss=CCE(),\n",
    "                        metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cc8fc727-b3cc-4529-94ca-cc2f43c217c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 1), output.shape=(None, 100)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[107], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mResidualNetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-UniversidadedaCoruña/carrera/3/1/ap/Ent_AP/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-UniversidadedaCoruña/carrera/3/1/ap/Ent_AP/lib/python3.11/site-packages/keras/src/backend/tensorflow/nn.py:587\u001b[0m, in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape, output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 \u001b[38;5;241m!=\u001b[39m e2:\n\u001b[0;32m--> 587\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    588\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must have the same shape. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    590\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    591\u001b[0m         )\n\u001b[1;32m    593\u001b[0m output, from_logits \u001b[38;5;241m=\u001b[39m _get_logits(\n\u001b[1;32m    594\u001b[0m     output, from_logits, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    595\u001b[0m )\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_logits:\n",
      "\u001b[0;31mValueError\u001b[0m: Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 1), output.shape=(None, 100)"
     ]
    }
   ],
   "source": [
    "ResidualNetwork.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a097afe3-0e8c-4033-b1bc-3833efd5f1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 16:29:53.377421: W tensorflow/core/framework/op_kernel.cc:1840] OP_REQUIRES failed at conv_ops_impl.h:668 : INVALID_ARGUMENT: convolution filter must be 4-dimensional: [0]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling Conv2D.call().\n\n\u001b[1m{{function_node __wrapped__Conv2D_device_/job:localhost/replica:0/task:0/device:CPU:0}} convolution filter must be 4-dimensional: [0] [Op:Conv2D]\u001b[0m\n\nArguments received by Conv2D.call():\n  • inputs=tf.Tensor(shape=(50000, 32, 32, 3), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[116], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mResidualNetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-UniversidadedaCoruña/carrera/3/1/ap/Ent_AP/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-UniversidadedaCoruña/carrera/3/1/ap/Ent_AP/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Exception encountered when calling Conv2D.call().\n\n\u001b[1m{{function_node __wrapped__Conv2D_device_/job:localhost/replica:0/task:0/device:CPU:0}} convolution filter must be 4-dimensional: [0] [Op:Conv2D]\u001b[0m\n\nArguments received by Conv2D.call():\n  • inputs=tf.Tensor(shape=(50000, 32, 32, 3), dtype=float32)"
     ]
    }
   ],
   "source": [
    "ResidualNetwork(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec35da2-f31a-4a58-aaec-01eaadeee711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c87a80-d839-45e0-96a3-736e5d574402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb43f991-938a-4107-ad25-4450153716d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d548ef44-4cd2-4277-bece-73e79f215729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992417e9-d96d-4b51-95da-2f440109cfc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5d323b8c-cf82-4890-bde6-6f13c3168aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c8bc3a-0984-47f7-b63d-c4b15d96252d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb31d96-b92e-4c40-a1d8-6980e3009761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219614e6-c085-423f-b700-e50ee031ec18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c24db6-6494-43ad-bcfc-ce998009e7a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df092082-9730-4bfc-8ff3-384b4bcbfd19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63907bae-e3cd-4f6d-8631-89169a6c1b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeca57ed-9991-4574-9515-55f55cdfed92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ent_AP",
   "language": "python",
   "name": "ent_ap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
