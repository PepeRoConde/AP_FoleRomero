{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "059185d0",
   "metadata": {},
   "source": [
    "# Práctica 1.1 - NNs (2024-2025) - Aprendizaje Profundo (Grado en IA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9118341c",
   "metadata": {},
   "source": [
    "|Integrantes|Correo electrónico|\n",
    "|-----------|------------------|\n",
    "|Hugo Fole Abellás|hugo.fole.abellas@udc.es|\n",
    "|José Romero Conde|j.rconde@udc.es|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f7523a",
   "metadata": {},
   "source": [
    "En esta práctica realizaremos un entrenamiento de una red neuronal. Dicha red será entrenada con el dataset **CIFAR-10**, el cual contiene 60.000 imágenes a color de tamaño 32×32 de las que 50.000 se usarán para el entrenamiento de la red y 10.000 para testearla. \n",
    "\n",
    "Las imágenes pertenecen a las 10 posibles categorı́as (6.000 imágenes por categorı́a)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5237b4",
   "metadata": {},
   "source": [
    "Inicialmente, importaremos las librerías a utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9feaaf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db204621-2798-4101-b3d5-1e0c76fbdaeb",
   "metadata": {},
   "source": [
    "A continuación, importaremos el dataset que será usado para entrenar la red que crearemos más adelante. Cabe recalcar que este dataset ya viene divido en dos lotes,como ya dijimos antes. Un lote de entrenamiento que contiene 50.000 instacias y otro de validación de 10.000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a58bb14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n",
    "(x_train, y_train) , (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3b2c2d-9407-4565-8868-4f9dfb85086e",
   "metadata": {},
   "source": [
    "## NORMALIZACIÓN DE LOS DATOS\n",
    "Para poder trabajar de manera correcta con este dataset, deberemos seguir ciertos procesos de normalización de datos, de manera que, o bien optimicemos su tiempo de ejecución o bien nos permita trabajar con el dataset. Estos procesos son :\n",
    "\n",
    "    1. Realizar One-hot encoding en los targets.\n",
    "    2. Normalizar los valores de las imágenes a float, ya que vienen en valores de 0 a 255.\n",
    "    3. Aplanar cada imagen para que sean vectores y no matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd007951-56fd-429e-96c0-1233ea643548",
   "metadata": {},
   "source": [
    "### 1. One-hot encoding\n",
    "Como ya comentamos, haremos one-hot en los targets de nuestro dataset ya que vienen divididos en 10 tipos de salidas categóricas representadas por números. Las diferentes salidas las podemos ver en la siguiente tabla.\n",
    "|Número|Categoría|\n",
    "|------|---------|\n",
    "|0|airplane|\n",
    "|1|automobile|\n",
    "|2|bird|\n",
    "|3|cat|\n",
    "|4|deer|\n",
    "|5|dog|\n",
    "|6|frog|\n",
    "|7|horse|\n",
    "|8|ship|\n",
    "|9|truck|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a744cab-d416-44af-bb3c-be1875a5947a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train[0][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed227e3e-7fcd-4bf6-b18e-e3ebe2f07335",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes = 10)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7892140d-2e0a-47ec-abdd-448600bb0865",
   "metadata": {},
   "source": [
    "#### 2.Normalización datos\n",
    "Como ya dijimos, en este apartado realizaremos la parte de normalización de datos de **uint8** con valores entre [0-255] a **float64**, para que pasen a estar en el rango de valores [0,1] ya que esto nos permite trabajar con redes de neuronas, agiliza el entrenamiento de dichas redes y aumenta la precisión de estas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e9d03ec-5bc9-465d-ade2-11c1251c5c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47537ae-0db9-42af-ac5f-4a552b908f36",
   "metadata": {},
   "source": [
    "#### 3. Aplanar las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d91910-f904-4714-978f-a3ada06b976e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b2e13ce-955a-4d69-8e46-ac44aaeb1505",
   "metadata": {},
   "source": [
    "### CREACIÓN RED NEURONAL Y ENTRENAMIENTO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76846a71-e902-4121-b214-daba24387bb5",
   "metadata": {},
   "source": [
    "Crearemos una red de neuronas artificiales densa, es decir, completamente conectada. Estudiaremos diversas composiciones y diversos hiperparámetros para saber cual sería el más óptimo para el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dbb881-e5f6-41dd-9aed-f2246edfdbd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
